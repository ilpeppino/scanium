{
  "uid": "scanium-openai-runtime",
  "title": "Scanium - OpenAI Runtime",
  "description": "Real-time OpenAI API metrics: requests, latency, tokens, errors, and rate limits",
  "tags": ["scanium", "openai", "ai", "llm", "assistant"],
  "timezone": "browser",
  "schemaVersion": 39,
  "version": 1,
  "refresh": "30s",
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "templating": {
    "list": [
      {
        "name": "model",
        "label": "Model",
        "type": "query",
        "datasource": { "type": "prometheus", "uid": "MIMIR" },
        "query": "label_values(openai_requests_total, model)",
        "refresh": 2,
        "includeAll": true,
        "multi": true,
        "current": { "text": "All", "value": "$__all" }
      }
    ]
  },
  "panels": [
    {
      "id": 1,
      "title": "Overview",
      "type": "row",
      "gridPos": { "x": 0, "y": 0, "w": 24, "h": 1 },
      "collapsed": false
    },
    {
      "id": 2,
      "title": "Request Rate",
      "description": "Requests per second to OpenAI API",
      "type": "stat",
      "gridPos": { "x": 0, "y": 1, "w": 6, "h": 4 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "sum(rate(openai_requests_total{model=~\"$model\"}[5m]))",
          "legendFormat": "req/s"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "decimals": 2,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 5 },
              { "color": "red", "value": 10 }
            ]
          }
        }
      },
      "options": {
        "graphMode": "area",
        "colorMode": "value"
      }
    },
    {
      "id": 3,
      "title": "p95 Latency",
      "description": "95th percentile request latency",
      "type": "stat",
      "gridPos": { "x": 6, "y": 1, "w": 6, "h": 4 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "histogram_quantile(0.95, sum by (le) (rate(openai_request_duration_seconds_bucket{model=~\"$model\"}[5m]))) * 1000",
          "legendFormat": "p95"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ms",
          "decimals": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 2000 },
              { "color": "red", "value": 5000 }
            ]
          }
        }
      },
      "options": {
        "graphMode": "area",
        "colorMode": "value"
      }
    },
    {
      "id": 4,
      "title": "Error Rate",
      "description": "Percentage of failed requests",
      "type": "stat",
      "gridPos": { "x": 12, "y": 1, "w": 6, "h": 4 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "100 * sum(rate(openai_requests_total{model=~\"$model\", status=\"error\"}[5m])) / sum(rate(openai_requests_total{model=~\"$model\"}[5m]))",
          "legendFormat": "error %"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "percent",
          "decimals": 1,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 1 },
              { "color": "red", "value": 5 }
            ]
          }
        }
      },
      "options": {
        "graphMode": "area",
        "colorMode": "value"
      }
    },
    {
      "id": 5,
      "title": "Tokens/Min",
      "description": "Total tokens consumed per minute",
      "type": "stat",
      "gridPos": { "x": 18, "y": 1, "w": 6, "h": 4 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "sum(rate(openai_tokens_total{model=~\"$model\", token_type=\"total\"}[5m])) * 60",
          "legendFormat": "tokens/min"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "decimals": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 50000 },
              { "color": "red", "value": 100000 }
            ]
          }
        }
      },
      "options": {
        "graphMode": "area",
        "colorMode": "value"
      }
    },
    {
      "id": 10,
      "title": "Request & Error Rates",
      "type": "row",
      "gridPos": { "x": 0, "y": 5, "w": 24, "h": 1 },
      "collapsed": false
    },
    {
      "id": 11,
      "title": "Request Rate by Model",
      "description": "Requests per second broken down by model",
      "type": "timeseries",
      "gridPos": { "x": 0, "y": 6, "w": 12, "h": 8 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "sum by (model) (rate(openai_requests_total{model=~\"$model\"}[5m]))",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "fillOpacity": 10,
            "showPoints": "never"
          }
        }
      }
    },
    {
      "id": 12,
      "title": "Errors by Type",
      "description": "Error rate by error type",
      "type": "timeseries",
      "gridPos": { "x": 12, "y": 6, "w": 12, "h": 8 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "sum by (error_type) (rate(openai_requests_total{model=~\"$model\", status=\"error\"}[5m]))",
          "legendFormat": "{{error_type}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "reqps",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "fillOpacity": 10,
            "showPoints": "never"
          }
        },
        "overrides": [
          {
            "matcher": { "id": "byName", "options": "RATE_LIMITED" },
            "properties": [{ "id": "color", "value": { "mode": "fixed", "fixedColor": "orange" } }]
          },
          {
            "matcher": { "id": "byName", "options": "UNAUTHORIZED" },
            "properties": [{ "id": "color", "value": { "mode": "fixed", "fixedColor": "red" } }]
          }
        ]
      }
    },
    {
      "id": 20,
      "title": "Latency",
      "type": "row",
      "gridPos": { "x": 0, "y": 14, "w": 24, "h": 1 },
      "collapsed": false
    },
    {
      "id": 21,
      "title": "Latency Percentiles",
      "description": "Request latency distribution",
      "type": "timeseries",
      "gridPos": { "x": 0, "y": 15, "w": 24, "h": 8 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "histogram_quantile(0.50, sum by (le) (rate(openai_request_duration_seconds_bucket{model=~\"$model\", status=\"success\"}[5m]))) * 1000",
          "legendFormat": "p50"
        },
        {
          "refId": "B",
          "expr": "histogram_quantile(0.95, sum by (le) (rate(openai_request_duration_seconds_bucket{model=~\"$model\", status=\"success\"}[5m]))) * 1000",
          "legendFormat": "p95"
        },
        {
          "refId": "C",
          "expr": "histogram_quantile(0.99, sum by (le) (rate(openai_request_duration_seconds_bucket{model=~\"$model\", status=\"success\"}[5m]))) * 1000",
          "legendFormat": "p99"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ms",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "fillOpacity": 0,
            "showPoints": "never"
          }
        }
      }
    },
    {
      "id": 30,
      "title": "Token Usage",
      "type": "row",
      "gridPos": { "x": 0, "y": 23, "w": 24, "h": 1 },
      "collapsed": false
    },
    {
      "id": 31,
      "title": "Token Rate by Type",
      "description": "Token consumption rate by input/output",
      "type": "timeseries",
      "gridPos": { "x": 0, "y": 24, "w": 12, "h": 8 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "sum by (token_type) (rate(openai_tokens_total{model=~\"$model\"}[5m])) * 60",
          "legendFormat": "{{token_type}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "fillOpacity": 10,
            "showPoints": "never"
          }
        },
        "overrides": [
          {
            "matcher": { "id": "byName", "options": "input" },
            "properties": [{ "id": "color", "value": { "mode": "fixed", "fixedColor": "blue" } }]
          },
          {
            "matcher": { "id": "byName", "options": "output" },
            "properties": [{ "id": "color", "value": { "mode": "fixed", "fixedColor": "green" } }]
          }
        ]
      }
    },
    {
      "id": 32,
      "title": "Token Rate by Model",
      "description": "Total token consumption by model",
      "type": "timeseries",
      "gridPos": { "x": 12, "y": 24, "w": 12, "h": 8 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "sum by (model) (rate(openai_tokens_total{model=~\"$model\", token_type=\"total\"}[5m])) * 60",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "fillOpacity": 10,
            "showPoints": "never"
          }
        }
      }
    },
    {
      "id": 40,
      "title": "Rate Limits",
      "type": "row",
      "gridPos": { "x": 0, "y": 32, "w": 24, "h": 1 },
      "collapsed": false
    },
    {
      "id": 41,
      "title": "Remaining Requests",
      "description": "Rate limit headroom for requests",
      "type": "timeseries",
      "gridPos": { "x": 0, "y": 33, "w": 12, "h": 8 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "openai_rate_limit_requests_remaining{model=~\"$model\"}",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "fillOpacity": 10,
            "showPoints": "auto"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "red", "value": 0 },
              { "color": "yellow", "value": 100 },
              { "color": "green", "value": 500 }
            ]
          }
        }
      }
    },
    {
      "id": 42,
      "title": "Remaining Tokens",
      "description": "Rate limit headroom for tokens",
      "type": "timeseries",
      "gridPos": { "x": 12, "y": 33, "w": 12, "h": 8 },
      "datasource": { "type": "prometheus", "uid": "MIMIR" },
      "targets": [
        {
          "refId": "A",
          "expr": "openai_rate_limit_tokens_remaining{model=~\"$model\"}",
          "legendFormat": "{{model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short",
          "custom": {
            "drawStyle": "line",
            "lineInterpolation": "smooth",
            "fillOpacity": 10,
            "showPoints": "auto"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "red", "value": 0 },
              { "color": "yellow", "value": 10000 },
              { "color": "green", "value": 50000 }
            ]
          }
        }
      }
    }
  ]
}
